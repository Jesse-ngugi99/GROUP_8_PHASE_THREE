{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12a767a-9992-4960-b4a3-8ce33a840852",
   "metadata": {},
   "source": [
    "# 1.0 **BUSINESS UNDERSTANDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424bc6f-84f2-42b4-94fa-d1fa5384d9d2",
   "metadata": {},
   "source": [
    "### 1.1 **BUSINESS OVERVIEW**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25763e-274a-4798-8613-ddc40ace5999",
   "metadata": {},
   "source": [
    "A telecom business involves the development, ownership or operation of telecommunication systems and services such as mobile communication, fixed-line services, and internet provision to a wide range of customers. Over the years, the telecom business has evolved rapidly because of technology shifts such as adoption of 5G networks, customer expectations, and stiff competition in the field.It can operate in diverse sectors, from software and e-commerce to fintech and biotechnology, but they are all united by a reliance on digital infrastructure and a data-driven approach.The business is often faced by challenges such as customer churn where the clients cancel subscriptions and move to competitors or even fraud cases such as unusual data activities in their sysytems. Due to intense competition in the sector, potential loopholes should be handled with utmost importance and consider decision making based on data-driven insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838e2834-6e71-4362-aa48-a4a62b5d22a1",
   "metadata": {},
   "source": [
    "### 1.2 **PROBLEM STATEMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7274ae2-b199-4c49-879b-16625170e6e3",
   "metadata": {},
   "source": [
    "In telecommunication companies such as SyriaTel, customer churn poses a significant risk to the companyâ€™s revenue and market position in a highly competitive sector. Retaining customers and maintaining high levels of satisfaction is crucial, as users often shift to alternative service providers that offer better service. The problem is that without understanding why customers leave, SyriaTel risks losing both users and revenue. This is because the company cannot effectively track and interpret customer behavior, which in turn prevents timely intervention. This project aims to lower the trend in revenue loss due to customer churn, where customers cancel or fail to renew subscriptions and switch to competitors. To address this issue, the company wants to utilize customer data and come up with data-driven insights that support better customer retention, reduce revenue loss, and enhance long-term business "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d8a83-42b3-4935-8aa7-2dc9f7ade062",
   "metadata": {},
   "source": [
    "### 1.3 **BUSINESS OBJECTIVES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233be2c-7d63-41de-af2b-7fe720594516",
   "metadata": {},
   "source": [
    "#### 1.3.1 **MAIN OBJECTIVE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51eaa7d-1f34-42cf-aee1-976abd4a0477",
   "metadata": {},
   "source": [
    "The main objective of this project is to help SyriaTel, a telecommunication company, reduce revenue loss caused by customer churn by developing a predictive model that identifies customers who are most likely to leave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5c8ea-5709-45cc-abd0-c2657eca7a75",
   "metadata": {},
   "source": [
    "#### 1.3.2 **SPECIFIC OBJECTIVES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fae06-eec1-40b3-8103-c9dd8d0c6eff",
   "metadata": {},
   "source": [
    "1. Explore the cutomer data to identify trends and patterns that influence churn.\n",
    "2. Preprocess the data by handling missing values, encoding categorical features and create new features with respect to customer behavior.\n",
    "3. Build and train diffent classification models that will predict customer churn.\n",
    "4. Evaluate the model perfomance.\n",
    "5. Identify the most significant features that will provide actionable insights with respect to churn.\n",
    "6. Provide recommendations to stakeholders for customer retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73437aad-9c94-4e16-8fb1-ce66566bbba0",
   "metadata": {},
   "source": [
    "#### 1.3.2 **RESEARCH QUESTIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38149bf-454a-408d-b458-54c9c9b56f6a",
   "metadata": {},
   "source": [
    "1. What are the key factors that influence churn at SyrilTel?\n",
    "2. Which classification model perfoms best to predict customer churn likelihood?\n",
    "3. How do customer usage habits, billing trends, and service experiences compare between churners and non-churners?\n",
    "4. Which strategies can be adopted by the company based on findings, to reduce churn and improve customer retention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed386d22-aad9-4531-8fe8-e4b854642c6f",
   "metadata": {},
   "source": [
    "### 1.3 **SUCCESS CRITERIA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c5df1-7ace-42a5-b964-2ebd830538e8",
   "metadata": {},
   "source": [
    "To build a classification model that:\n",
    "- Predicts whether a customer is likely to stay or churn.\n",
    "- Provides interpretable insights into the key factors influencing churn, to support customer retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb9cfb-6852-469d-b30f-68d3387debc5",
   "metadata": {},
   "source": [
    "# 2.0 **DATA UNDERSTANDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ab888-065c-4763-b509-57c17ec0c816",
   "metadata": {},
   "source": [
    "- The dataset was sourced from Kaggle. (https://www.kaggle.com/datasets/becksddf/churn-in-telecoms-dataset)\n",
    "- It consists of 3333 records and 21 fields.\n",
    "- The dataset consists of float, integer, boolean, and object data types.\n",
    "- The dataset contains information on customer data across different states, including their usage behavior, subscription plans, and churn status.\n",
    "- The column names are:\n",
    "   1. **State**   -state where the customer resides             \n",
    "   2. **Account length**   -Period the customer has had the account for.      \n",
    "   3. **Area code**      -Telephone area code of the customer\n",
    "   4. **Phone number**      -   Customer's telephone number\n",
    "   5. **International plan**     -Whether the customer has an international calling plan (yes/no)\n",
    "   6. **Voice mail plan**       -Whether the customer has a voice mail plan (yes/no)\n",
    "   7. **Number vmail messages**   -Number of voicemail messages sent or received\n",
    "   8. **Total day minutes**    -  Total minutes of calls made during the day\n",
    "   9. **Total day calls**   -     Total number of calls made during the day\n",
    "   10. **Total day charge**    - Total charges for daytime calls\n",
    "   11. **Total eve minutes**-Total minutes of calls made during the evening\n",
    "   12. **Total eve  calls** -Total number of calls made during the evening\n",
    "   13. **Total eve charge**     -Total charges for evening calls\n",
    "   14. **Total night minutes**     -Total minutes of calls made during the night\n",
    "   15. **Total night calls**   -Total number of calls made during the night\n",
    "   16. **Total night charge**     -Total charges for night calls\n",
    "   17. **Total intl minutes**   -Total minutes spent on international calls.-\n",
    "   18. **Total intl calls**    -Total number of international calls.\n",
    "   19. **Total intl charge**  -   Total cost charged for international calls.\n",
    "   20. **Customer service calls**-Number of times the customer called customer service.\n",
    "   21. **Churn**   -Whether the customer left the company             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902f1ff-f989-42fd-a8ab-f9888b57bebc",
   "metadata": {},
   "source": [
    "# 3.0 **DATA PREPARATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c73cab-5c25-4839-a00d-951ea24e6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   #for data manipulation and analysis.\n",
    "import numpy as np    #for numeric and scientific computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7636b4-22ce-4ea7-a660-328e90d8d57b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bigml_59c28831336c6604c800002a.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigml_59c28831336c6604c800002a.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m#load the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bigml_59c28831336c6604c800002a.xls'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.xls\")  #load the dataset\n",
    "df.head() #preview the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4697921-75e7-4036-be8e-f9cd6fee6d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()  #Gives an overview of the dataframe's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888c243-ef99-4740-b07f-76f66f4b6170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()    #Gives a statistical summary of the dataframe.(Focuses on numerical columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e06a5f-4ac4-45cf-b1be-688912673887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum() #Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de39f4-075c-4ed0-a82e-4c33a5838184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() #Check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb2835-4b66-42c2-9388-a066012ca484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['phone number']=df['phone number'].str.replace(r'[^\\d]','',regex=True) #This replaces all non-digits in the phone number column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e828fa1-dce4-43f6-881f-efbb18d517b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn']=df['churn'].astype(int) #This converts the column from 'boolean' data type to 'int' for better model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e53d7-d280-4f93-9c94-7ae454a3bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['state','area code','phone number'],axis=1) #drop 'irrelevant' columns.They only identify the customer and have no predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b28ee-d046-4f6d-978d-100bc7100554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6353a-91df-4a86-9fee-ada3f81faa4a",
   "metadata": {},
   "source": [
    "# 4.0 **DATA ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ee4b2-e0c6-48b1-acad-c641ec9a6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c681f-d78e-40bf-af2d-6ac8a944c619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1=df.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1cbf7-b4c5-4f1f-bfb6-592c03eb3e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation matrix of all features in the dataset\n",
    "Corr_matrix=df1.corr(numeric_only=True)\n",
    "Corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a5008-1497-4a56-84d9-5660f7ac9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot feature correlation matrix\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(Corr_matrix,cmap='Blues',vmin=-1,vmax=1,annot=True)\n",
    "plt.title('FEATURE CORRELATION MATRIX',fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46608b7a-d216-43e0-8f92-582eb791dd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #correlation between the target variable('churn') and the predictive features.\n",
    "corr=df1.corr(numeric_only=True)[['churn']].sort_values(by='churn',ascending=False) \n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748a357-cce6-4b9f-ade5-0b635cf7ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Target correlation matrix.\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr,cmap='coolwarm',vmin=-1,vmax=1,annot=True)\n",
    "plt.title('TARGET CORRELATION MATRIX',fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc24578-05bb-4127-834a-3ef8da2c7b49",
   "metadata": {},
   "source": [
    "- From the correlation  matrix above, it is clear that charges and minutes columns are redundant because of similar correlation with each other. Churn interprets them as similar information.\n",
    "- From this inference, we drop the minutes columns and analyse user data based on billing rather than usage time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ae9bd-3861-429b-bf04-ca99dcd2783b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create new minutes and charges columns, each containing the total \n",
    "df1['Total_minutes']=(df1['total day minutes']+df1['total eve minutes']+df1['total night minutes']+df1['total intl minutes'])\n",
    "df1['Total_charges']=(df1['total day charge']+df1['total eve charge']+df1['total night charge']+df1['total intl charge'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac000e-3935-4874-aa6b-0b56a7864c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of numeric features\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "numeric_features = ['total day charge','total eve charge','total night charge','total intl charge','number vmail messages','account length',]\n",
    "plt.figure(figsize=(18, 15))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(5, 2, i)\n",
    "    sns.histplot(df[feature], bins=30, kde=True, color=\"skyblue\")\n",
    "    plt.title(f\"{feature} Distribution\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ba050-882d-42a0-8799-2de158fa804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a scatter plot to confirm Linearity of the two variables\n",
    "df1.plot.scatter('Total_minutes','Total_charges')\n",
    "plt.title(\"Total day minutes vs Total day charge\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c7ef5-c018-4240-909b-ce80c3d73e8d",
   "metadata": {},
   "source": [
    "- **This confirms the linearity between the two variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fde79f-1cf6-4a22-95b1-e771abfc72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the 'minutes' columns.\n",
    "df1=df1.drop(columns=['Total_minutes','total day minutes','total eve minutes','total night minutes','total intl minutes'],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427a26c-d37e-4039-91db-e4f9dfd4c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_rate=df1['churn'].mean()*100  #Calculates the overall churn rate (percentage of customers who churned).\n",
    "churn_by_int_plan=round(df1.groupby('international plan')['churn'].mean()*100,2) #Gives churn rate for customers with and without an international plan\n",
    "churn_by_int_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e510410-733c-40c9-b4a9-82087e046af2",
   "metadata": {},
   "source": [
    "- **Customers subscribed to the international plan show a churn rate of 42.4%, compared to 11.5% for those without it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a8fb3-1d8d-409e-bd41-3e1b0ded2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=churn_by_int_plan.index, y=churn_by_int_plan.values,palette='viridis')\n",
    "plt.title('Churn Rate by International Plan', fontweight='bold')\n",
    "plt.ylabel('Churn Rate(%)',fontweight='bold')\n",
    "plt.xlabel('International Plan',fontweight='bold');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1faed4d-4160-4d09-9dec-2e72a32beee5",
   "metadata": {},
   "source": [
    "- **Customers with an international plan are more likely to churn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e9972-27bf-458d-bc3c-dbc39ade474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_by_plans = df1.groupby(['international plan', 'voice mail plan'])['churn'].mean() * 100\n",
    "print(churn_by_plans.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe5705-cbfd-44f2-970b-fdf688860d45",
   "metadata": {},
   "source": [
    "- **Customers with a voice mail plan have a lower churn rate compared to those without.**\n",
    "- **This indicates that this additional service 'voicemail' may contribute to higher retention of customers.**\n",
    "- **Customers with an international plan but with no voice mail plan are likely to leave**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193f569-b2b9-4fdf-8ba5-fa89fcb0150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at voice mail plan column to understand its distribution\n",
    "churns_by_voice_mail_plan =df.groupby(\"voice mail plan\")[\"churn\"].mean().reset_index()\n",
    "sns.barplot( data=churns_by_voice_mail_plan, x=\"voice mail plan\", y=\"churn\",palette='viridis' )\n",
    "plt.title(\"churn by Voice mail Plan\")\n",
    "plt.xlabel(\"Voice mail plan\")\n",
    "plt.ylabel(\"churn rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc7957-0d41-4bd6-aeb1-c7d4fa945597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "churn_by_customer_service_Calls=round(df.groupby('customer service calls')['churn'].mean()*100,2)\n",
    "churn_by_customer_service_Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314aa2f3-6ac5-42eb-89bd-6cde1ea44f4d",
   "metadata": {},
   "source": [
    "**Churn rates increase with the number of customer service calls.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b2be5-aa1d-4b4f-94e1-802c7ac8680a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=churn_by_customer_service_Calls.index, y=churn_by_customer_service_Calls,palette='viridis')\n",
    "plt.title('Churn by Customer Service Calls', fontweight='bold')\n",
    "plt.ylabel('Churn Rate(%)', fontweight='bold')\n",
    "plt.xlabel('Customer service calls', fontweight='bold');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fc7cd-29f3-45b4-aec2-d5bd2cf7de05",
   "metadata": {},
   "source": [
    "**Customers that contacted customer servives churned more, indicating a possible dissatisfaction in the services, such as unresolved issues, or long delays in resolving the issues.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a9946-499b-40ee-a39a-c3086e39856e",
   "metadata": {},
   "source": [
    "# 5.0 **MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278bd9bf-d9c3-425f-9410-688826697c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   #Imports Logistic Regression model.\n",
    "from sklearn.model_selection import train_test_split  #Function to split data into training and testing sets.\n",
    "import statsmodels.api as sm                          #Statsmodels library for advanced statistical modeling and summaries.\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7c09c-4cda-4d5c-ab5d-ff79ea872219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b204c-3a30-4709-84dd-0c542e383864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the target and predictive features.\n",
    "y=df1['churn']\n",
    "X=df1.drop(['churn','account length'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e217e4-57fe-4a16-8edf-5ef40e3e60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts() #This check for class imbalance in our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf734f-4a64-45fc-9612-72da8469d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the class balance.\n",
    "sns.countplot(x='churn', data=df1)  #plots a countplot\n",
    "plt.title(\"Churn Counts\",fontweight='bold')\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646f096-667a-4672-b86f-944508ae2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test data.\n",
    "#The 'stratify' parameter ensures there is a class balance between train and test sets.\n",
    "#70% of data goes to train set, 30% to test set.\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3066478-8c99-4cb7-bcf5-b0ad31814387",
   "metadata": {},
   "source": [
    "#### **PREPROCESS THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7e8d3-4b37-46b9-bb0f-0d4f95296804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some data preprocessing steps such as encoding and feature scaling occur in this step and not the previous one(Data preparation)\n",
    "#to prevent data leakage where information outside training data leaks into the model during training, inflating the model perfomance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc44e6-1e9a-4c59-a80b-a9abcf49e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=X.select_dtypes(include='object').columns\n",
    "numeric_columns=X.select_dtypes(include=['float64','int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca84c7f-8003-459c-bef7-6a77d1d3d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical variables.\n",
    "from sklearn.preprocessing import OneHotEncoder                                            # import the OneHotEncoder library\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False, dtype='int')      # Initializes the encoder\n",
    "categorical_cols = ['international plan', 'voice mail plan']                               # Categorical column names\n",
    "encoded_train = ohe.fit_transform(X_train[categorical_cols])                               # Fit and transform on train\n",
    "encoded_feature_names = ohe.get_feature_names_out(categorical_cols)                        # Get new column names\n",
    "df_encoded_train = pd.DataFrame(encoded_train, columns=encoded_feature_names, index=X_train.index)  # Convert encoded array into DataFrame\n",
    "X_train_enc = pd.concat([X_train.drop(columns=categorical_cols), df_encoded_train], axis=1) # Merge encoded features with original dataset\n",
    "encoded_test = ohe.transform(X_test[categorical_cols])                                     # Transform test using same encoder\n",
    "df_encoded_test = pd.DataFrame(encoded_test, columns=encoded_feature_names, index=X_test.index)    # Convert encoded array into DataFrame\n",
    "X_test_enc = pd.concat([X_test.drop(columns=categorical_cols), df_encoded_test], axis=1)   # Merge encoded features with original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29c043-216b-4d23-8439-f8c5ca50a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler=StandardScaler()                          #Initialize the scaler\n",
    "X_train_scaled=scaler.fit_transform(X_train_enc) #Fit the scaler on training data and transform it\n",
    "X_test_scaled=scaler.transform(X_test_enc)       #Transform the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77cd76-806e-4e66-ae92-4f26afbe4585",
   "metadata": {},
   "source": [
    "#### **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1420e-bad0-4d86-9d1e-7dd6c3a8c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This gives a statistical summary of the features.\n",
    "X_train_enc = sm.add_constant(X_train_enc) #Adds a constant column to the features\n",
    "model = sm.Logit(y_train, X_train_enc)     #Defines the logistic regression model\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77e2f3-762d-4934-af2c-d62bd338ac41",
   "metadata": {},
   "source": [
    "- From the LLR p-value, the overall model is statistically significant.\n",
    "- The total day calls, eve calls, and night calls have very small coefficients, (not significant) meaning call counts donâ€™t strongly affect churn.\n",
    "- Strong churn drivers are Customer service calls and International plan which is evident from their p-values.\n",
    "- The model may not have fully optimized possibly due to multicollinearity or scaling issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabd1d3-403d-44fd-a7c6-1d9d37b91df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(solver='liblinear',max_iter=1000)  #Initialize Logistic Regression model\n",
    "logreg.fit(X_train_scaled,y_train)                           #Fit model on train set\n",
    "y_pred = logreg.predict(X_test_scaled)                       #Predict churn on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27edbb-2941-44a7-9c87-41fdcbfa1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay #import library\n",
    "cfm=confusion_matrix(y_test,y_pred)                #\n",
    "labels=['stayed','churned']\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cfm,display_labels=labels)\n",
    "\n",
    "disp.plot(cmap='Blues');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd67bd2-80e6-4f95-973f-d6666002fb7a",
   "metadata": {},
   "source": [
    "- **The model has 828 True negatives meaning it correctly predicted 828 non-churners**\n",
    "- **The model has 38 True positives meaning it correctly predicts 38 churners**\n",
    "- **The model has 107 False negatives meaning model wrongly classified 107 churners as non-churners**\n",
    "- **The model has 27 False negatives meaning it wrongly classified  27 non-churners as churners**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7006ad-57d2-41c3-8a8d-8402f7fbf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06558e06-0b73-476b-a7df-dcc00fbc2f36",
   "metadata": {},
   "source": [
    "- **The model has an accuracy of about 87% meaning it correctly predicts churn for 87% of users in the dataset**\n",
    "- **Precision for class 0(non-churners: Model is correct 89% of the times it predicts non-churners)**\n",
    "- **Recall for class 0 (non-churners): Model captures 97%  of actual non-churners**\n",
    "- **Precision for class 1 (churners: Model is correct 58% of the times it predicts churners)**\n",
    "- **Recall for class 1 (churners): Model captures 26%  of actual churners**\n",
    "- **F1-score for churners (0.36) is significantly low which indicates a poor balance between recall and precision**\n",
    "\n",
    "From above inferences, it is concluded that the model is biased towards the majority class likely due to class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbc438-4337-48af-b246-c8fec82a43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll try and balance the model with class weights in logistic regression.\n",
    "logreg=LogisticRegression(class_weight='balanced',solver='liblinear',max_iter=1000)  #Initialize Logistic Regression model\n",
    "logreg.fit(X_train_scaled,y_train)                                                   #Fit model on train set\n",
    "y_pred = logreg.predict(X_test_scaled)                                               #Predict churn on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe64b71-67a8-44d3-94ff-5face662a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay #import library\n",
    "cfm=confusion_matrix(y_test,y_pred)                #\n",
    "labels=['stayed','churned']\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cfm,display_labels=labels)\n",
    "disp.plot(cmap='Blues');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06612e04-ac54-4fe3-ab4f-81aa29c8a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3afed6-be62-40ff-a47b-c54ad647c0a9",
   "metadata": {},
   "source": [
    "- **The model has an accuarcy of about 76% meaning it correctly predicts churn for 76% of users in the dataset. This is slightly lower than the unbalanced model since it takes the churners class more seriously**\n",
    "- **Precision for class 0(non-churners: Model is correct 95% of the times it predicts non-churners)**\n",
    "- **Recall for class 0 (non-churners): Model captures 77%  of actual non-churners**\n",
    "- **Precision for class 1 (churners: Model is correct 35% of the times it predicts churners)**\n",
    "- **Recall for class 1 (churners): Model captures 74%  of actual churners**\n",
    "\n",
    "- **Recall for churn shifted from 0.26 to 0.74, meaning the model catches most churner but with more false positives.**\n",
    "- **This trade-off is acceptable in this churn analysis because missing a churner is expensive than wrongly flagging a loyal customer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ba6cd-6085-413f-93c7-178f3d06455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "from sklearn.metrics import RocCurveDisplay \n",
    "RocCurveDisplay.from_estimator(logreg, X_test_scaled, y_test)\n",
    "plt.title(\"ROC Curve (Logistic Regression)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f76d7-d7d5-4d86-bae3-474bf4bf837e",
   "metadata": {},
   "source": [
    "- The curve shows the trade-off between recall and specificity at different thresholds.\n",
    "- An AUC of 0.82 means the model does well at distinguisshing churners and non-churners apart. If you randomly pick one customer who churned and one who didnâ€™t, thereâ€™s about an 82% chance the model will give the churner a higher score than the non-churner.\n",
    "- The model is fairly reliable at ranking customers by their likelihood to churn.\n",
    "- The higher the AUC, the better the separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf3492-84a7-41a6-b416-807cfbfad776",
   "metadata": {},
   "source": [
    "**From this analysis, we decide to keep the Logistic regression as our baseline model, as we shift to a new model to test whether perfomance will improve.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ebfa0-5180-423a-b76f-02204780353a",
   "metadata": {},
   "source": [
    "#### **DECISION TREES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd4ef8-896a-4fcc-9424-155ab13e94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tree= DecisionTreeClassifier(max_depth=5, random_state=42)  # limit depth to avoid overfitting\n",
    "Tree.fit(X_train_scaled, y_train)\n",
    "y_pred_tree = Tree.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07e787-d469-462a-b28d-f6c203de93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"Accuracy:\", Tree.score(X_test_scaled, y_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tree))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d1250-19e1-454f-b931-3ff1aacd9286",
   "metadata": {},
   "source": [
    "* The model has an overall accuracy: 96.7%  meaning the model correctly predicts churn status for most customers.\n",
    "* Class 0 (non-churners): Very high recall (100%) and precision (96%), meaning almost all non-churners are correctly identified.\n",
    "* Class 1 (churners): Precision is high (98%) but recall is lower (79%), while most predicted churners are correct, some actual churners are missed.\n",
    "* F1-scores: 0.98 for non-churners, 0.87 for churners â€” indicating the model performs better for non-churners at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8a93e-37b7-479c-966d-a0ea1c19d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_tree),display_labels=['Stayed','Churned'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8477bb-90c1-4d76-b1b8-24ae1813a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "acc = Tree.score(X_test_scaled, y_test)* 100\n",
    "print('Accuracy is :{0}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd798f64-2c69-4d57-a821-690f567e6669",
   "metadata": {},
   "source": [
    "* The model has 853 True negatives meaning the model correctly predicted 853 non-churners\n",
    "* The model has 114 True positives meaning the model correctly predicts 114 churners\n",
    "* The model has 31 False negatives meaning model wrongly detected 31 churners as non-churners\n",
    "* The model has 2 False positive meaning it wrongly classified 2 non-churners as churners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcdab7-ecb3-4689-8f98-f62a8ef433fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_Tree = Tree.predict_proba(X_test_scaled)[:, 1] #predict_proba gives two columns: [P(class=0), P(class=1)], [:, 1] selects only the probabilities for churn.\n",
    "roc_auc = roc_auc_score(y_test, y_pred_Tree)         #Gives predicted probabilities for the churn class.  \n",
    "print(\"Decision Tree AUC:\", round(roc_auc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994dffb-99e5-4c91-939b-fb13d19110a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC curve\n",
    "RocCurveDisplay.from_estimator(Tree, X_test_scaled, y_test)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray') #Adds the diagonal line\n",
    "plt.title(\"Decision Tree ROC Curve \")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe859f47-5949-4c68-9ca0-1ea75becf4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebe386-5c88-486a-8d0f-0b5024ae1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting the decision tree\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(15,12))\n",
    "plot_tree(Tree, feature_names=X_train_enc.columns,filled=True, rounded=True, fontsize=10,max_depth=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb097e06-2ac4-438f-8048-16bce8608cd9",
   "metadata": {},
   "source": [
    "- Customer service calls is the strongest predictor\n",
    "- Less frequent calls, customer is likely to stay.\n",
    "- Frequent calls trigger strong churn risk.\n",
    "- International plan is the major driver of churn\n",
    "- Customers with international plans churn more often (maybe due to cost).\n",
    "- Heavy international spenders are at greater churn risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b984226-c65a-4cf6-a597-a35f1f7e302f",
   "metadata": {},
   "source": [
    "- The tree shows service dissatisfaction (service calls) and billing (international plan/charges) as main churn contributors. \n",
    "- Most churners come from customers who:\n",
    "  - **Seek support from customer services often**\n",
    "  - **Have an international plan**\n",
    "  - **Accumulate higher international charges**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9839d-6957-4164-8a0a-b3d43bf5fb0f",
   "metadata": {},
   "source": [
    "###  Handling data imbalance by SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a6047-2c43-4d02-8ed8-5e84af1f0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a85f7-ca9c-4678-b066-278b32baf21d",
   "metadata": {},
   "source": [
    "### Traning the model with the resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0966b1c-04a5-4254-a958-b439579719d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree on resampled data\n",
    "tree_smote = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree_smote.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512ce36-8e82-4f3a-ada2-a47932649770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform  prediction on the resampled data\n",
    "y_pred = tree_smote.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b31430-5ad1-41ab-87a6-608f678d5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding out the accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a174743-9226-40df-b66f-141872a4bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred),display_labels=['Stayed','Churned'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.gca().grid(False) #Removes the gridlines\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1823075-1bd6-4860-8a55-7e7002953709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report on resampled data\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd7c9f-1f4b-4980-8d36-2feab2f1aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the decision tree of the resampled data \n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_smote,feature_names=X.columns,class_names=[\"stayed\", \"Churn\"],filled=True, rounded=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc67fe3-9347-4742-9562-b24070fd3a7e",
   "metadata": {},
   "source": [
    "- The second model (resampled data ) is the better choice because, in churn problems, missing churners (false negatives) is far worse than having a few false alarms. This model is excellent at catching churners, with a recall of 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae920d0-48be-4749-8dfe-3686a7ea558b",
   "metadata": {},
   "source": [
    "# 6.0 **EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2345b15-7fbf-4cd1-a8fb-7a2d1cb8dfc0",
   "metadata": {},
   "source": [
    "#### **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d3bc0-6cb1-475a-921e-c78202b7d114",
   "metadata": {},
   "source": [
    "- Has better generalization on test data,(Accuracy: 86.6% ) before balancing. This indicates Logistic Regression handles unseen data more reliably compared to the decision trees.\n",
    "- Model highlights key churn drivers clearly from the Coefficients obtained. They show that:\n",
    "  - International plan has a strong positive association with churn (customers with international plans are more likely to churn).\n",
    "  - Customer service calls strongly increase churn likelihood as frustrated customers are more likely to leave\n",
    "- Logistic Regression provides transparent evidence for stakeholders.\n",
    "- Unlike decision trees that only show whether the customer churned or stayed, Logistic Regression gives a probability score e.g 80% chance of churn. This is useful because you can rank customers by risk and target the ones most likely to leave with retention offers.\n",
    "- Logistic Regression is less likely to overfit since it uses a simple linear form and regularization, making it more reliable on messy, real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3667ac7b-071b-490e-afe1-01155db6b51d",
   "metadata": {},
   "source": [
    "#### **DECISION TREES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbeee07-945a-4297-851c-e551ffa3a104",
   "metadata": {},
   "source": [
    "- The AUC of 0.88 is significantly high meaning the Decision Tree has strong ability to separate churners from non-churners. If you randomly select one churner and one non-churner, thereâ€™s an 88% chance the tree will correctly assign a higher churn probability to the churner.\n",
    "- The curve rises steeply at the start meaning the model quickly captures a lot of true churners while keeping false positives low.\n",
    "- The curve then flattens indicating a trade-off. As the threshold decreases, the model starts misclassifying more non-churners as churners but still, the overall curve stays well above the diagonal (random guessing line), which confirms good discriminative power.\n",
    "- The tree can be useful in churn prediction where the company can rank customers by churn risk and target top-risk groups with retention offers.\n",
    "- Compared to Logistic Regression (AUC = 0.82), this tree performs better in terms of separating churners vs non-churners, but LR may generalize more reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac5faf-4dbc-464f-ab63-08b0be890ca2",
   "metadata": {},
   "source": [
    "# 7.0 **CONCLUSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e3cf8-f221-4a1c-ad8f-e75719977127",
   "metadata": {},
   "source": [
    "- Customers who frequently contact customer service are more likely to churn, while those with few service calls are less likely to leave. This suggests that repeated calls may reflect dissatisfaction or unresolved issues.\n",
    "\n",
    "- When customers have many service calls combined with high total daytime charges, the probability of churn becomes even higher, showing a stronger pattern of frustration.\n",
    "\n",
    "- Customers without a voice mail plan and with high daytime charges are more likely to churn. On the other hand, those with a voice mail plan and high daytime usage are more likely to stay, suggesting that the voice mail plan adds value and increases satisfaction.\n",
    "\n",
    "- Customers who have an international plan and high daytime charges are also at a higher risk of churning, possibly due to high costs or unmet expectations with international services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4873f-4830-41b0-b473-bc0f8392f40b",
   "metadata": {},
   "source": [
    "# 8.0 **RECOMMENDATIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79778ab6-2cc8-450c-9ee1-c0f24a761c25",
   "metadata": {},
   "source": [
    "- **The company should improve customer services** as customers who call support often may be unhappy. The company should review the customer service process to solve problems faster and reduce repeated calls.\n",
    "\n",
    "- **Company should come up with a retention plan for international users** as customers with international plans and high daytime usage are more likely to leave. The company can create special offers, discounts, or loyalty rewards for these customers to keep them satisfied.\n",
    "\n",
    "- **Promotion of  voicemail plans**: Regular daytime callers without voicemail plans are more likely to churn. The company should encourage these customers to take voicemail plans, maybe through bundled promotions.\n",
    "\n",
    "- **Company should have proactive outreach** where they contact high-usage customers before they complain by offering check-ins or small perks to make them feel valued and reduce the chance of churn.\n",
    "\n",
    "- **Develop targeted communication** such as sending personalized messages to at-risk groups like frequent service callers, heavy international users while explaining benefits of staying and giving tailored offers.\n",
    "\n",
    "- **Analyze call costs** as high daytime and international charges may frustrate customers. Reviewing pricing structures or offering flexible packages could reduce dissatisfaction.\n",
    "\n",
    "- **Customer education** as some customers may not fully understand plan benefits. Educating them in different ways such as explaining how voicemail or bundled offers save money, can improve satisfaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
